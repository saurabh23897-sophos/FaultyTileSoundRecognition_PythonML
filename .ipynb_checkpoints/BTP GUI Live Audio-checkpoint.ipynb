{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "import numpy as np\n",
    "import pyqtgraph as pg\n",
    "import pyaudio\n",
    "from PyQt5 import QtCore, QtGui\n",
    "\n",
    "FS = 16000 #Hz\n",
    "\n",
    "D = 1\n",
    "S = 2\n",
    "FRAMESZ = int(FS*S/D)\n",
    "AMPRNGE = int(65536/256+1)\n",
    "CHUNKSZ = int(FS/50) #samples\n",
    "FPS = int(FS/CHUNKSZ)\n",
    "\n",
    "IMG = np.zeros((FRAMESZ, AMPRNGE)).astype('int8')\n",
    "count = 0\n",
    "\n",
    "class MicrophoneRecorder():\n",
    "    def __init__(self, signal):\n",
    "        self.signal = signal\n",
    "        self.p = pyaudio.PyAudio()\n",
    "        self.stream = self.p.open(format=pyaudio.paInt16,\n",
    "                            channels=1,\n",
    "                            rate=FS,\n",
    "                            input=True,\n",
    "                            frames_per_buffer=CHUNKSZ)\n",
    "\n",
    "    def read(self):\n",
    "        data = self.stream.read(CHUNKSZ)\n",
    "        y = np.fromstring(data, 'int16')\n",
    "        self.signal.emit(y)\n",
    "\n",
    "    def close(self):\n",
    "        self.stream.stop_stream()\n",
    "        self.stream.close()\n",
    "        self.p.terminate()\n",
    "\n",
    "class SpectrogramWidget(pg.PlotWidget):\n",
    "    read_collected = QtCore.pyqtSignal(np.ndarray)\n",
    "    def __init__(self):\n",
    "        super(SpectrogramWidget, self).__init__()\n",
    "\n",
    "        self.img = pg.ImageItem()\n",
    "        self.addItem(self.img)\n",
    "\n",
    "        self.img_array = IMG\n",
    "        self.show()\n",
    "\n",
    "    def update(self, chunk):\n",
    "        buffer = chunk\n",
    "        #print(chunk)\n",
    "        chunk = np.divide(chunk, 256).astype('int8')\n",
    "        chunk = np.add(chunk, int(65536/256/2))\n",
    "#        chunk = np.pad(chunk, (0,D-L%D), 'constant')\n",
    "        chunk = chunk.reshape((-1, D))\n",
    "        chunk = np.mean(chunk, axis=1).astype('int8')\n",
    "\n",
    "        self.img_array = np.roll(self.img_array, FRAMESZ-int(CHUNKSZ/D), 0)\n",
    "        self.img_array[FRAMESZ-int(CHUNKSZ/D):FRAMESZ, :] = 255\n",
    "        self.img_array[FRAMESZ-int(CHUNKSZ/D):FRAMESZ, chunk] = 0\n",
    "\n",
    "        self.img.setImage(self.img_array)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = QtGui.QApplication([])\n",
    "    w = SpectrogramWidget()\n",
    "    w.read_collected.connect(w.update)\n",
    "\n",
    "    mic = MicrophoneRecorder(w.read_collected)\n",
    "\n",
    "    # time (seconds) between reads\n",
    "\n",
    "    t = QtCore.QTimer()\n",
    "\n",
    "    t.timeout.connect(mic.read)\n",
    "    t.start(int(1000/FPS)) #QTimer takes ms\n",
    "\n",
    "\n",
    "    app.exec_()\n",
    "    mic.close()\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
